{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "neoLUTO Data Preparation\n",
    "========================\n",
    "\n",
    "Required input files:\n",
    "\n",
    "* cell_LU_mapping.h5\n",
    "* cell_zones_df.h5\n",
    "* cell_livestock_data.h5\n",
    "* SA2_crop_data.h5\n",
    "* cell_biophysical_df.h5\n",
    "* NLUM_SPREAD_LU_ID_Mapped_Concordance.h5\n",
    "* SA2_climate_damage_mult.h5\n",
    "\n",
    "* tmatrix-categories.csv\n",
    "* tmatrix-cat2lus.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "From `cell_LU_mapping.h5` the following are obtained:\n",
    "* CELLS_SA2 -- CELL_ID-SA2_ID concordance table.\n",
    "* LANDUSES -- lexicographically ordered list of land-uses (strings).\n",
    "* LUMAP -- present (2010) land-use mapping.\n",
    "* LMMAP -- present (2010) land-management mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File cell_LU_mapping.h5 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-157284022e52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cell_LU_mapping.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib64/python3.10/site-packages/pandas/io/pytables.py\u001b[0m in \u001b[0;36mread_hdf\u001b[0;34m(path_or_buf, key, mode, errors, where, start, stop, columns, iterator, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path_or_buf} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHDFStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File cell_LU_mapping.h5 does not exist"
     ]
    }
   ],
   "source": [
    "lmap = pd.read_hdf('cell_LU_mapping.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CELLS_SA2 (concordance table) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure the CELL_ID starts at zero, rather than one.\n",
    "lmap.reset_index(inplace=True)\n",
    "lmap = lmap.rename(columns={'CELL_ID': 'CELL_ID_PLUSONE'})\n",
    "lmap = lmap.rename(columns={'index': 'CELL_ID'})\n",
    "\n",
    "# Select the appropriate columns.\n",
    "concordance = lmap[['CELL_ID', 'SA2_ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Write concordance to CSV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "concordance.to_csv('cells-sa2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LANDUSES (lexicographically ordered list of land-uses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distill the lexicographically ordered list of land-uses.\n",
    "landuses = sorted(lmap['LU_DESC'].unique().to_list())\n",
    "landuses.remove('Non-agricultural land') # Remove this non land-use.\n",
    "\n",
    "# Distill a LU_ID to LU_DESC concordance table.\n",
    "luid2desc = lmap.groupby('LU_ID').first()['LU_DESC']\n",
    "luid2desc = luid2desc.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write land-use list to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(landuses).to_csv('landuses.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write land-use list to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('landuses.npy', np.array(landuses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write LU_ID to LU_DESC concordance to HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "luid2desc.to_hdf('luid2desc.hdf5', key='luid2desc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LUMAP (land-use mapping) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where the land-uses are on the map.\n",
    "locations = lmap['LU_DESC'].to_numpy()\n",
    "\n",
    "# Create a highpos-style lumap. Use -1 for anything _not_ in the land-use list.\n",
    "lucodes = [-1 if (r not in landuses) else landuses.index(r) for r in locations]\n",
    "lumap = np.array(lucodes, dtype=np.int8)\n",
    "\n",
    "# Certain land-uses are not available.\n",
    "# nal = landuses.index('Non-agricultural land')\n",
    "# plf = landuses.index('Plantation forestry')\n",
    "# lumap = np.where((lumap==nal) | (lumap==plf), -1, lumap)\n",
    "lumap_pd = pd.DataFrame(lumap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write lumap to CSV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumap_pd = lumap_pd.rename(columns={0: 'j'})\n",
    "lumap_pd.to_csv('lumap.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write lumap to NPY ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lumap.npy', lumap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMMAP (land-management mapping) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For now only 'rain-fed' ('dry' == 0) and 'irrigated' ('irr' == 1) available.\n",
    "lmmap = lmap['IRRIGATION']\n",
    "lmmap_np = lmmap.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write lmmap to CSV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lmmap.to_csv('lmmap.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write lmmap to NPY ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('lmmap.npy', lmmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `cell_zones_df.h5` the following are obtained:\n",
    "* REAL_AREA -- hectares per given cell, corrected for projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = pd.read_hdf('cell_zones_df.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REAL_AREA (hectares per cell, projection corrected) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_area = zones['CELL_HA']\n",
    "real_area_np = real_area.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write real_area to CSV ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_area.to_csv('real-area.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write real_area to NPY ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save('real-area.npy', real_area_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POTENTIAL_IRRIGATION_AREAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_irrigation_areas = zones['POTENTIAL_IRRIGATION_AREAS'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write potential_irrigation_areas to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('potential-irrigation-areas.npy', potential_irrigation_areas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in from-to costs in category-to-category format.\n",
    "tmcat = pd.read_csv('tmatrix-categories.csv', index_col=0)\n",
    "# Read the categories to land-uses concordance.\n",
    "cat2lus = pd.read_csv('tmatrix-cat2lus.csv').to_numpy()\n",
    "# Produce a dictionary for ease of look up.\n",
    "l2c = dict([(row[1], row[0]) for row in cat2lus])\n",
    "# Prepare indices.\n",
    "indices = [(lu1, lu2) for lu1 in landuses for lu2 in landuses]\n",
    "# Prepare the DataFrame.\n",
    "t = pd.DataFrame(index=landuses, columns=landuses, dtype=np.float64)\n",
    "# Fill the DataFrame.\n",
    "for i in indices: t.loc[i] = tmcat.loc[l2c[i[0]], l2c[i[1]]]\n",
    "# Switching to existing land use (i.e. not switching) does not cost anything.\n",
    "for lu in landuses: t.loc[lu, lu] = 0\n",
    "# Extract the actual tmatrix Numpy array.\n",
    "tmatrix = t.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write TMATRIX to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tmatrix.npy', tmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIV SPATIAL DATA\n",
    "\n",
    "Obtained from:\n",
    "* cell_livestock_data.h5\n",
    "* SA2_crop_data.h5\n",
    "* cell_biophysical_df.h5 (from cell_biophysical_df.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvstk = pd.read_hdf('cell_livestock_data.h5')\n",
    "crops = pd.read_hdf('SA2_crop_data.h5')\n",
    "bioph = pd.read_hdf('cell_biophysical_df.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_req = ( lvstk[['FEED_REQ', 'CELL_ID']]\n",
    "             .groupby('CELL_ID')\n",
    "             .first()['FEED_REQ']\n",
    "             .to_numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasture_kg_dm_ha = ( lvstk[['PASTURE_KG_DM_HA', 'CELL_ID']]\n",
    "                     .groupby('CELL_ID')\n",
    "                     .first()['PASTURE_KG_DM_HA']\n",
    "                     .to_numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_pur_natl = ( lvstk[['SAFE_PUR_NATL', 'CELL_ID']]\n",
    "                  .groupby('CELL_ID')\n",
    "                  .first()['SAFE_PUR_NATL']\n",
    "                  .to_numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_pur_modl = ( lvstk[['SAFE_PUR_MODL', 'CELL_ID']]\n",
    "                  .groupby('CELL_ID')\n",
    "                  .first()['SAFE_PUR_MODL']\n",
    "                  .to_numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crops[['SA2_ID', 'WP']].groupby('SA2_ID').first()\n",
    "wpc = concordance.merge( c\n",
    "                       , left_on='SA2_ID'\n",
    "                       , right_on='SA2_ID'\n",
    "                       , how='left' )['WP']\n",
    "wpl = lvstk['WP']\n",
    "water_delivery_price = np.where(np.isnan(wpc), wpl, wpc)\n",
    "water_licence_price = bioph['WATER_PRICE_ML_BOM'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_over_175mm = bioph['AVG_GROW_SEAS_PREC_GE_175_MM_YR'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write feed_req to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('feed-req', feed_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write pasture_kg_dm_ha to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pasture-kg-dm-ha', pasture_kg_dm_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write safe_pur_natl to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('safe-pur-natl', safe_pur_natl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write safe_pur_modl to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('safe-pur-modl', safe_pur_modl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write water_delivery_price to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('water-delivery-price.npy', water_delivery_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('water-licence-price.npy', water_licence_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write prec_over_175mm to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prec-over-175mm.npy', prec_over_175mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXCLUDE MATRICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `NLUM_SPREAD_LU_ID_Mapped_Concordance.h5` the following are obtained:\n",
    "\n",
    "* x_mrj -- exclude matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the 'ultimate truth' table.\n",
    "ut = pd.read_hdf('NLUM_SPREAD_LU_ID_Mapped_Concordance.h5')\n",
    "\n",
    "# Turn it into a pivot table. Non-NaN entries are allowed land-uses in the SA2.\n",
    "ut_ptable = ut.pivot_table( index='SA2_ID'\n",
    "                          , columns=['IRRIGATION', 'LU_DESC']\n",
    "                          )['LU_ID']\n",
    "x_dry = concordance.merge( ut_ptable[0]\n",
    "                         , left_on='SA2_ID', right_on='SA2_ID'\n",
    "                         , how='left')\n",
    "x_irr = concordance.merge( ut_ptable[1]\n",
    "                         , left_on='SA2_ID', right_on='SA2_ID'\n",
    "                         , how='left')\n",
    "x_dry = x_dry.drop(columns=['CELL_ID', 'SA2_ID'])\n",
    "x_irr = x_irr.drop(columns=['CELL_ID', 'SA2_ID'])\n",
    "\n",
    "# Some land uses never occur at all\n",
    "# like dry-land pears and rice, grazing on irrigated natural land.\n",
    "for lu in landuses:\n",
    "    if lu not in x_dry.columns:\n",
    "        x_dry[lu] = np.nan\n",
    "    if lu not in x_irr.columns:\n",
    "        x_irr[lu] = np.nan\n",
    "\n",
    "# 'Unallocated - modified land' can occur anywhere but is never irrigated.\n",
    "x_dry['Unallocated - modified land'] = 22\n",
    "x_irr['Unallocated - modified land'] = np.nan\n",
    "\n",
    "# 'Unallocated - natural land' is never irrigated. Occurs where t_mrj allows it. \n",
    "x_dry['Unallocated - natural land'] = 23\n",
    "x_irr['Unallocated - natural land'] = np.nan\n",
    "\n",
    "# Ensure lexicographical order.\n",
    "x_dry.sort_index(axis='columns', inplace=True)\n",
    "x_irr.sort_index(axis='columns', inplace=True)\n",
    "\n",
    "# Turn into Numpy arrays.\n",
    "x_dry = x_dry.to_numpy()\n",
    "x_irr = x_irr.to_numpy()\n",
    "\n",
    "# Turn into 'boolean' arrays.\n",
    "x_dry = np.where(np.isnan(x_dry), 0, 1)\n",
    "x_irr = np.where(np.isnan(x_irr), 0, 1)\n",
    "\n",
    "# The land uses in the 'cropping' categories.\n",
    "cropping_lus = [ 'Hay'\n",
    "               , 'Other non-cereal crops'\n",
    "               , 'Summer cereals'\n",
    "               , 'Summer legumes'\n",
    "               , 'Summer oilseeds'\n",
    "               , 'Winter cereals'\n",
    "               , 'Winter legumes'\n",
    "               , 'Winter oilseeds'\n",
    "               , 'Cotton'\n",
    "               , 'Rice'\n",
    "               , 'Sugar'\n",
    "               , 'Vegetables' ]\n",
    "clus = [ landuses.index(lu) for lu in cropping_lus ]\n",
    "\n",
    "# Dryland cropping only if precipitation is over 175mm in growth season.\n",
    "x_dry[:, clus] *= prec_over_175mm[:, np.newaxis]\n",
    "\n",
    "# Irrigated land-usage is only allowed in potential irrigation areas.\n",
    "x_irr *= potential_irrigation_areas[:, np.newaxis]\n",
    "\n",
    "# Stack for neoLUTO use.\n",
    "x_mrj = np.stack((x_dry, x_irr)).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write exclude matrices to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('x-mrj.npy', x_mrj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the required columns.\n",
    "rivregs = zones[['HR_RIVREG_ID', 'HR_RIVREG_NAME']].copy()\n",
    "\n",
    "# Make sure the cell ids are zero-based.\n",
    "rivregs['LUTO_ID'] = rivregs.index\n",
    "\n",
    "# Reorder columns.\n",
    "rivregs = rivregs[['LUTO_ID', 'HR_RIVREG_ID', 'HR_RIVREG_NAME']]\n",
    "\n",
    "# Select the required columns.\n",
    "draindivs = zones[['HR_DRAINDIV_ID', 'HR_DRAINDIV_NAME']].copy()\n",
    "\n",
    "# Make sure the cell ids are zero-based.\n",
    "draindivs['LUTO_ID'] = draindivs.index\n",
    "\n",
    "# Reorder columns.\n",
    "draindivs = draindivs[['LUTO_ID', 'HR_DRAINDIV_ID', 'HR_DRAINDIV_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_yield_baselines = bioph[['WATER_YIELD_DR_ML_HA', 'WATER_YIELD_SR_ML_HA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write rivregs to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rivregs.to_hdf( 'rivregs.hdf5', key='rivregs'\n",
    "              , mode='w', format='table', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write draindivs to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "draindivs.to_hdf( 'draindivs.hdf5', key='draindivs'\n",
    "                , mode='w', format='table', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write water_yield_baselines to HDF5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_yield_baselines.to_hdf( 'water-yield-baselines.hdf5', key='water_yieldbase_lines'\n",
    "                            , mode='w', format='table', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLIMATE IMPACTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/pandas/core/frame.py:9191: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (1 levels on the left,3 on the right)\n",
      "  return merge(\n"
     ]
    }
   ],
   "source": [
    "# Load raw climate impact data.\n",
    "cci_raw = pd.read_hdf('SA2_climate_damage_mult.h5')\n",
    "\n",
    "# Distill available RCPs.\n",
    "rcps = {col[0] for col in cci_raw.columns}\n",
    "\n",
    "for rcp in rcps:\n",
    "    # Slice off RCP and turn into pivot table.\n",
    "    cci_ptable = cci_raw[rcp].pivot_table( index='SA2_ID'\n",
    "                                         , columns=['IRRIGATION', 'LU_ID'] )\n",
    "\n",
    "    # Merge with SA2-Cell concordance to obtain cell-based pivot table.\n",
    "    cci = concordance.merge( cci_ptable\n",
    "                           , left_on='SA2_ID', right_on='SA2_ID'\n",
    "                           , how='left')\n",
    "\n",
    "    # Not all columns are needed.\n",
    "    cci = cci.drop(['CELL_ID', 'SA2_ID'], axis=1)\n",
    "\n",
    "    # Land-uses as strings and years as integers.\n",
    "    lmid2desc = {0: 'dry', 1: 'irr'}\n",
    "    coltups = [ (int(col[0][3:]), lmid2desc[col[1]], luid2desc[col[2]])\n",
    "                for col in cci.columns ]\n",
    "    mcolumns = pd.MultiIndex.from_tuples(coltups)\n",
    "    cci.columns = mcolumns\n",
    "    \n",
    "    # Arrange levels of multi-index as (lm, lu, year).\n",
    "    cci = cci.swaplevel(0,1, axis='columns')\n",
    "    cci = cci.swaplevel(1,2, axis='columns')\n",
    "    cci.sort_index(axis=1, inplace=True)\n",
    "    \n",
    "    # Write to HDF5 file.\n",
    "    fname = 'climate-change-impacts-' + rcp + '.hdf5'\n",
    "    kname = 'climate_change_impacts_' + rcp \n",
    "    cci.to_hdf( fname, key=kname , mode='w', format='table'\n",
    "              , complevel=9, index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agec_crops(concordance, data, columns=None, lus=None, lms=None):\n",
    "    \"\"\"Return LUTO-cell wise, multi-indexed column-landuse-landman DataFrame.\"\"\"\n",
    "\n",
    "    # If no list of columns is provided, infer it from provided data.\n",
    "    if columns is None:\n",
    "        columns = data.columns.to_list()\n",
    "\n",
    "    # If no list of land uses provided, infer it from the SPREAD_CLASS column.\n",
    "    if lus is None:\n",
    "        lus = sorted(data['LU_DESC'].unique().tolist())\n",
    "\n",
    "    # If no list of land managements provided, use irrigation status only.\n",
    "    if lms is None:\n",
    "        lms = ['dry', 'irr']\n",
    "\n",
    "    # Produce a multi-indexed version data and merge to yield cell-based table.\n",
    "    crops_ptable = data.pivot_table( index='SA2_ID'\n",
    "                                   , columns=['Irrigation', 'LU_DESC'] )\n",
    "    agec_crops = concordance.merge( crops_ptable\n",
    "                                  , left_on='SA2_ID'\n",
    "                                  , right_on=crops_ptable.index\n",
    "                                  , how='left' )\n",
    "\n",
    "    # Some columns have to go.\n",
    "    agec_crops = agec_crops.drop(['CELL_ID', 'SA2_ID'], axis=1)\n",
    "\n",
    "    # The merge flattens the multi-index to tuples, so unflatten here.\n",
    "    ts = [(t[0], lms[t[1]], t[2]) for t in agec_crops.columns]\n",
    "    agec_crops.columns = pd.MultiIndex.from_tuples(ts)\n",
    "\n",
    "    return agec_crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agec_lvstk(data):\n",
    "    \"\"\"Return LUTO-cell wise, multi-indexed column-landuse DataFrame.\"\"\"\n",
    "\n",
    "    # Get only the columns that vary with the land-use.\n",
    "    animals = [ c for c in data.columns if 'BEEF' in c\n",
    "                                        or 'SHEEP' in c\n",
    "                                        or 'DAIRY' in c ]\n",
    "    agec_lvstk = data[animals]\n",
    "\n",
    "    # Prepare columns for multi-indexing, i.e. turn into a list of tuples.\n",
    "    cols = agec_lvstk.columns.to_list()\n",
    "    cols = [tuple(c.split(sep='_')) for c in cols]\n",
    "    cols = [(c[0]+'_'+c[1], c[2]) if c[0]=='WR' else c for c in cols]\n",
    "    cols = [ (c[0] + '_' + c[1] + '_' + c[3] + '_' +c[4], c[2])\n",
    "             if c[0]=='FEED' else c for c in cols ]\n",
    "\n",
    "    # Make and set the multi-index.\n",
    "    mcolindex = pd.MultiIndex.from_tuples(cols)\n",
    "    agec_lvstk.columns = mcolindex\n",
    "\n",
    "    return agec_lvstk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concordance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-69509f3a5875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magec_crops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_agec_crops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcordance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0magec_lvstk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_agec_lvstk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvstk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concordance' is not defined"
     ]
    }
   ],
   "source": [
    "agec_crops = build_agec_crops(concordance, crops)\n",
    "agec_lvstk = build_agec_lvstk(lvstk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agec_crops.to_hdf( 'input/agec-crops-c9.hdf5', 'agec_crops'\n",
    "                 , mode='w'\n",
    "                 , format='table'\n",
    "                 , complevel=9\n",
    "                 , index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agec_lvstk.to_hdf( 'agec-lvstk-c9.hdf5', 'agec_lvstk'\n",
    "                 , mode='w'\n",
    "                 , format='table'\n",
    "                 , complevel=9\n",
    "                 , index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
